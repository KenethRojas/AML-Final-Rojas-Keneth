# Modelo de PropensiÃ³n para la AdquisiciÃ³n de un Seguro Vehicular (Advanced ML)

Proyecto de **clasificaciÃ³n binaria** para predecir la probabilidad de que un cliente adquiera un **seguro vehicular**, usando un dataset tabular anonimizado (30,000 registros, 10 variables predictoras + ID + target). El objetivo es mejorar la eficiencia de campaÃ±as comerciales priorizando a los clientes con mayor propensiÃ³n.

---

## ğŸ§  Problema y Objetivo

**Problema:** Una empresa de seguros desea anticipar quÃ© clientes tienen mayor probabilidad de adquirir un seguro vehicular para optimizar sus campaÃ±as comerciales y mejorar la conversiÃ³n.

**Objetivo:** Entrenar un modelo predictivo (clasificaciÃ³n binaria) que estime la **propensiÃ³n de compra** y permita:
- Priorizar clientes con mayor probabilidad o leads (ej. top deciles).
- Reducir costo por contacto.
- Mejorar conversiÃ³n enfocando esfuerzos en perfiles con mayor intenciÃ³n.

---

## ğŸ“¦ Dataset

- **TamaÃ±o:** 30,000 filas Ã— 12 columnas  
- **Target:** `Flag_Vehicular` (0 = no compra, 1 = compra)  
- **Desbalance:** ~94% clase 0 vs ~6% clase 1 (ratio ~15.7:1)  
- **Variables:** `Variable1` a `Variable10` (anonimizadas), `cliente` como identificador tÃ©cnico.

> Nota: El dataset fue provisto internamente por la empresa aseguradora como parte del caso de estudio. Por motivos de confidencialidad, la informaciÃ³n se entrega anonimizada: no contiene datos personales identificables (por ejemplo, nombres, documentos, telÃ©fonos, direcciones) y las variables han sido enmascaradas con nombres genÃ©ricos (Variable1 a Variable10). Asimismo, el identificador cliente funciona Ãºnicamente como un ID tÃ©cnico para trazabilidad y validaciones, sin permitir la identificaciÃ³n real de un individuo. Esta anonimizaciÃ³n asegura el cumplimiento de buenas prÃ¡cticas de privacidad y permite realizar el modelamiento sin exponer informaciÃ³n sensible del negocio.

---

## ğŸ§° MetodologÃ­a (resumen)

1. **EDA**: DistribuciÃ³n del target, correlaciones, anÃ¡lisis de outliers.
2. **Preprocesamiento**:
   - No hubo missing values.
   - Tratamiento de outliers con winsorizaciÃ³n (1%â€“99%) en variables continuas.
   - Escalado con `RobustScaler`.
   - Split estratificado train/val/test (70/15/15).
3. **Modelos**:
   - **Deep Learning (PyTorch)**: MLP densa (64 â†’ 32 â†’ 16) con BatchNorm + ReLU + Dropout.
   - **Baselines (sklearn)**: Logistic Regression y Random Forest.
4. **EvaluaciÃ³n**:
   - MÃ©tricas de clasificaciÃ³n (Accuracy / Precision / Recall / F1 + matriz de confusiÃ³n).
   - ComparaciÃ³n contra baselines.

---

## âœ… Resultados y mÃ©tricas principales

- El dataset estÃ¡ **altamente desbalanceado**, por lo que **Accuracy puede ser engaÃ±osa**.
- En la comparaciÃ³n de modelos, los baselines (especialmente Random Forest) obtuvieron mejor desempeÃ±o global que la red neuronal en la corrida final.
- La matriz de confusiÃ³n muestra que el reto principal estÃ¡ en **capturar adecuadamente la clase minoritaria (compradores)** sin disparar falsos positivos.

### MÃ©trica principal usada (clasificaciÃ³n)
- **Accuracy** (y reporte de clasificaciÃ³n con Precision/Recall/F1)

### ComparaciÃ³n de modelos (Test)
| Modelo | MÃ©trica (Accuracy) |
|-------|---------------------|
| Random Forest | **0.9416** |
| Logistic Regression | **0.9402** |
| Deep Learning (MLP) | **0.7044** |

> RecomendaciÃ³n: para una evaluaciÃ³n mÃ¡s justa en desbalance, priorizar **Recall/F1 de la clase 1**, ademÃ¡s de **PR-AUC/ROC-AUC** y ajuste de umbral.

---

## ğŸ¯ Conclusiones y Valor para la Toma de Decisiones

- El proyecto demuestra un pipeline completo de **modelado de propensiÃ³n** (end-to-end).
- Para este dataset, **Random Forest** y **Logistic Regression** alcanzan mejor desempeÃ±o global que el DL en accuracy.
- A nivel negocio, el output del modelo permite:
  - Identificar clientes con mayor probabilidad de compra.
  - Priorizar esfuerzos comerciales (contacto, ofertas, seguimiento).
  - Mejorar el ROI de campaÃ±as al reducir el gasto en segmentos con baja propensiÃ³n.

---

## ğŸ“ Estructura del repositorio
* `notebooks/` â†’ Notebook principal del proyecto
* `src/` â†’ CÃ³digo auxiliar (opcional)
* `data/` â†’ Solo instrucciones del dataset (no subir datos grandes)
* `results/` â†’ Resultados y mÃ©tricas
* `figures/` â†’ GrÃ¡ficos generados
* `report/` â†’ Reporte final (PDF o Markdown)

---

## ğŸš€ CÃ³mo ejecutar

### OpciÃ³n A: Google Colab (recomendado)
1. Sube el notebook a Colab.
2. Monta tu Google Drive.
3. Coloca el dataset en la ruta esperada.
4. Ejecuta todas las celdas en orden.

### OpciÃ³n B: Local (Jupyter)
1. Crea un entorno virtual.
2. Instala dependencias.
3. Ejecuta el notebook.

---

## ğŸ”§ Dependencias

Principales librerÃ­as usadas:
- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `scikit-learn`
- `torch` (PyTorch)
- (opcional) `shap`

---

## ğŸ“Œ PrÃ³ximas mejoras

- Manejo explÃ­cito del desbalance:
- `class_weight` / `pos_weight`,
- oversampling (SMOTE) o undersampling con cuidado de leakage.
- Ajuste de **umbral de decisiÃ³n** segÃºn capacidad comercial.
- MÃ©tricas adicionales: **PR-AUC, ROC-AUC**, curva Precision-Recall, calibraciÃ³n.
- Interpretabilidad:
- SHAP con el pipeline correcto (y sample representativo),
- importancia por permutaciÃ³n en baselines.

---

## ğŸ‘¤ Autor

**Keneth Anderson Rojas Cadillo**  
Capstone Project â€“ Advanced Machine Learning

---

## ğŸ“š Referencias (base)

- Scikit-learn documentation (modelos y mÃ©tricas).
- PyTorch documentation (arquitectura y entrenamiento).
- SHAP documentation (interpretabilidad).

---

## ğŸ“„ Licencia

Uso acadÃ©mico / educativo.
Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

