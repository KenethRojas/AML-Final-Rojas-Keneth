# Modelo de PropensiÃ³n para la AdquisiciÃ³n de un Seguro Vehicular (Advanced ML)

Proyecto de **clasificaciÃ³n binaria** para predecir la probabilidad de que un cliente adquiera un **seguro vehicular**, usando un dataset tabular anonimizado (30,000 registros, 10 variables predictoras + ID + target). El objetivo es mejorar la eficiencia de campaÃ±as comerciales priorizando a los clientes con mayor propensiÃ³n.

---

## ğŸ§  Contexto y objetivo de negocio

En seguros, contactar clientes de forma masiva incrementa costos y reduce ROI. Este proyecto construye un modelo que **estima propensiÃ³n de compra** para:
- priorizar leads (ej. top deciles),
- reducir costo por contacto,
- mejorar conversiÃ³n enfocando esfuerzos en perfiles con mayor intenciÃ³n.

---

## ğŸ“¦ Dataset

- **TamaÃ±o:** 30,000 filas Ã— 12 columnas  
- **Target:** `Flag_Vehicular` (0 = no compra, 1 = compra)  
- **Desbalance:** ~94% clase 0 vs ~6% clase 1 (ratio ~15.7:1)  
- **Variables:** `Variable1` a `Variable10` (anonimizadas), `cliente` como identificador tÃ©cnico.

> Nota: El dataset fue provisto internamente por la empresa aseguradora como parte del caso de estudio. Por motivos de confidencialidad, la informaciÃ³n se entrega anonimizada: no contiene datos personales identificables (por ejemplo, nombres, documentos, telÃ©fonos, direcciones) y las variables han sido enmascaradas con nombres genÃ©ricos (Variable1 a Variable10). Asimismo, el identificador cliente funciona Ãºnicamente como un ID tÃ©cnico para trazabilidad y validaciones, sin permitir la identificaciÃ³n real de un individuo. Esta anonimizaciÃ³n asegura el cumplimiento de buenas prÃ¡cticas de privacidad y permite realizar el modelamiento sin exponer informaciÃ³n sensible del negocio.

---

## ğŸ§° MetodologÃ­a (resumen)

1. **EDA**: distribuciÃ³n del target, correlaciones, anÃ¡lisis de outliers.
2. **Preprocesamiento**:
   - no hubo missing values,
   - tratamiento de outliers con winsorizaciÃ³n (1%â€“99%) en variables continuas,
   - escalado con `RobustScaler`,
   - split estratificado train/val/test (70/15/15).
3. **Modelos**:
   - **Deep Learning (PyTorch)**: MLP densa (64 â†’ 32 â†’ 16) con BatchNorm + ReLU + Dropout.
   - **Baselines (sklearn)**: Logistic Regression y Random Forest.
4. **EvaluaciÃ³n**:
   - mÃ©tricas de clasificaciÃ³n (Accuracy / Precision / Recall / F1 + matriz de confusiÃ³n),
   - comparaciÃ³n contra baselines.

---

## âœ… Resultados (alto nivel)

- El dataset estÃ¡ **altamente desbalanceado**, por lo que **Accuracy puede ser engaÃ±osa**.
- En la comparaciÃ³n de modelos, los baselines (especialmente Random Forest) obtuvieron mejor desempeÃ±o global que la red neuronal en la corrida final.
- La matriz de confusiÃ³n muestra que el reto principal estÃ¡ en **capturar adecuadamente la clase minoritaria (compradores)** sin disparar falsos positivos.

> RecomendaciÃ³n: para una evaluaciÃ³n mÃ¡s justa en desbalance, priorizar **Recall/F1 de la clase 1**, ademÃ¡s de **PR-AUC/ROC-AUC** y ajuste de umbral.

---

## ğŸ“ Estructura del repositorio
* `notebooks/` â†’ Notebook principal del proyecto
* `src/` â†’ CÃ³digo auxiliar (opcional)
* `data/` â†’ Solo instrucciones del dataset (no subir datos grandes)
* `results/` â†’ Resultados y mÃ©tricas
* `figures/` â†’ GrÃ¡ficos generados
* `report/` â†’ Reporte final (PDF o Markdown)

---

## ğŸš€ CÃ³mo ejecutar

### OpciÃ³n A: Google Colab (recomendado)
1. Sube el notebook a Colab.
2. Monta tu Google Drive.
3. Coloca el dataset en la ruta esperada
4. Ejecuta todas las celdas en orden.

### OpciÃ³n B: Local (Jupyter)
1. Crea un entorno virtual.
2. Instala dependencias.
3. Ejecuta el notebook.

---

## ğŸ”§ Dependencias

Principales librerÃ­as usadas:
- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `scikit-learn`
- `torch` (PyTorch)
- (opcional) `shap`

---

## ğŸ“Œ PrÃ³ximas mejoras

- Manejo explÃ­cito del desbalance:
- `class_weight` / `pos_weight`,
- oversampling (SMOTE) o undersampling con cuidado de leakage.
- Ajuste de **umbral de decisiÃ³n** segÃºn capacidad comercial.
- MÃ©tricas adicionales: **PR-AUC, ROC-AUC**, curva Precision-Recall, calibraciÃ³n.
- Interpretabilidad:
- SHAP con el pipeline correcto (y sample representativo),
- importancia por permutaciÃ³n en baselines.

---

## ğŸ‘¤ Autor

**Keneth Anderson Rojas Cadillo**  
Capstone Project â€“ Advanced Machine Learning

---

## ğŸ“š Referencias (base)

- Scikit-learn documentation (modelos y mÃ©tricas).
- PyTorch documentation (arquitectura y entrenamiento).
- SHAP documentation (interpretabilidad).

---

## ğŸ“„ Licencia

Uso acadÃ©mico / educativo.
Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

